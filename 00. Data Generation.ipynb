{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c5550f5-f066-400d-8fa2-d448b99c5026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "544a9f79-a8b2-4c79-b347-2bc4fbc91a87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14ebf725-0d6e-408c-8d83-edb0821ba9e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcadee35-6769-4921-b9ea-01e0550e8bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set catalog and schema\n",
    "catalog = \"jack_sandom\"\n",
    "schema = \"ai_audience_segments\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35a6a737-cbc0-4b1e-95e6-0cf32d19d74e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Generate structured data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e7d271-1442-4836-8b99-5f478c593440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4840f56b-9dd6-41e1-b240-5be1ac97917d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We need to use conditional probabilities in our data gen code in order to \"force\" the clusters for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3176e5c5-498b-49ce-bb15-4f7289f09a87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining our clusters and sizes\n",
    "cluster_sizes = {\n",
    "  \"Young Urban Professional\": 250,\n",
    "  \"Suburban Family-Oriented\": 250,\n",
    "  \"Retired Rural Dweller\": 150,\n",
    "  \"College Student\": 150,\n",
    "  \"High-Income Empty Nester\": 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e371ed8b-4976-4824-afe4-2a09c856b15f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate correlated data per cluster\n",
    "def generate_cluster_data(cluster_name, size):\n",
    "    if cluster_name == \"Young Urban Professional\":\n",
    "        ages = np.random.randint(25, 35, size)\n",
    "        incomes = np.random.normal(50000, 10000, size).clip(30000, 150000)\n",
    "        locations = [\"Urban\"] * size\n",
    "        education_levels = np.random.choice([\"Bachelor's\", \"Post Graduate\"], size, p=[0.6, 0.4])\n",
    "        relationship_statuses = np.random.choice([\"Single\", \"Cohabiting\"], size, p=[0.6, 0.4])\n",
    "        number_dependants = np.random.choice([0, 1], size, p=[0.8, 0.2])\n",
    "        occupations = np.random.choice([\"Professional\", \"Executive\"], size, p=[0.7, 0.3])\n",
    "\n",
    "    elif cluster_name == \"Suburban Family-Oriented\":\n",
    "        ages = np.random.randint(35, 50, size)\n",
    "        incomes = np.random.normal(50000, 10000, size).clip(40000, 150000)\n",
    "        locations = [\"Suburban\"] * size\n",
    "        education_levels = np.random.choice([\"Some College\", \"Bachelor's\", \"Post Graduate\"], size, p=[0.3, 0.5, 0.2])\n",
    "        relationship_statuses = [\"Cohabiting\"] * size\n",
    "        number_dependants = np.random.choice([1, 2, 3, 4], size, p=[0.3, 0.4, 0.2, 0.1])\n",
    "        occupations = np.random.choice([\"Professional\", \"Skilled Trades\"], size, p=[0.6, 0.4])\n",
    "\n",
    "    elif cluster_name == \"Retired Rural Dweller\":\n",
    "        ages = np.random.randint(60, 81, size)\n",
    "        incomes = np.random.normal(40000, 5000, size).clip(20000, 60000)\n",
    "        locations = [\"Rural\"] * size\n",
    "        education_levels = np.random.choice([\"High School\", \"Some College\", \"Bachelor's\", \"Post Graduate\"], size, p=[0.5, 0.3, 0.1, 0.1])\n",
    "        relationship_statuses = np.random.choice([\"Cohabiting\", \"Widowed\"], size, p=[0.7, 0.3])\n",
    "        number_dependants = np.random.choice([0, 1], size, p=[0.8, 0.2])\n",
    "        occupations = [\"Retired\"] * size\n",
    "\n",
    "    elif cluster_name == \"College Student\":\n",
    "        ages = np.random.randint(18, 22, size)\n",
    "        incomes = np.random.normal(20000, 3000, size).clip(0, 40000)\n",
    "        locations = [\"Urban\"] * size\n",
    "        education_levels = [\"Some College\"] * size\n",
    "        relationship_statuses = [\"Single\"] * size\n",
    "        number_dependants = [0] * size\n",
    "        occupations = [\"Student\"] * size\n",
    "\n",
    "    elif cluster_name == \"High-Income Empty Nester\":\n",
    "        ages = np.random.randint(50, 65, size)\n",
    "        incomes = np.random.normal(120000, 20000, size).clip(80000, 200000)\n",
    "        locations = [\"Suburban\"] * size\n",
    "        education_levels = np.random.choice([\"Bachelor's\", \"Post Graduate\"], size, p=[0.5, 0.5])\n",
    "        relationship_statuses = [\"Cohabiting\"] * size\n",
    "        number_dependants = [0] * size\n",
    "        occupations = np.random.choice([\"Executive\", \"Professional\"], size, p=[0.5, 0.5])\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"age\": ages,\n",
    "        \"income\": incomes.round(-3),\n",
    "        \"location\": locations,\n",
    "        \"education\": education_levels,\n",
    "        \"relationship_status\": relationship_statuses,\n",
    "        \"number_dependants\": number_dependants,\n",
    "        \"occupation\": occupations,\n",
    "        \"segment\": cluster_name\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1585a834-ca6c-48ae-a17a-fdb7c4b3701e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate data for all clusters\n",
    "cluster_dfs = [generate_cluster_data(cluster, size) for cluster, size in cluster_sizes.items()]\n",
    "demographic_df = pd.concat(cluster_dfs, ignore_index=True)\n",
    "\n",
    "# Shuffle data\n",
    "demographic_df = demographic_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Add UUID\n",
    "demographic_df.insert(0, 'uuid', [str(uuid.uuid4()) for _ in range(len(demographic_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c46e72-3a3a-4f2c-a321-80d65bda031a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demographic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77068db6-d72d-4c1b-8751-bb80b0ddbc2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Generate social media posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f1a78cd-e843-4640-ada8-1d7fab292f61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get random sample from demographic data\n",
    "sampled_df = demographic_df.sample(n=100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e897bd7-7f69-4b33-90b0-738a326a223f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define segment-specific products and possible emotions\n",
    "segment_products = {\n",
    "    \"Young Urban Professional\": [\"smartphone\", \"laptop\", \"smartwatch\", \"wireless earbuds\", \"fitness tracker\"],\n",
    "    \"Suburban Family-Oriented\": [\"family SUV\", \"grill\", \"home security system\", \"washing machine\", \"family board game\"],\n",
    "    \"Retired Rural Dweller\": [\"gardening tools\", \"golf clubs\", \"heating blanket\", \"armchair\", \"bird feeder\"],\n",
    "    \"College Student\": [\"backpack\", \"coffee maker\", \"gaming console\", \"textbooks\", \"bicycle\"],\n",
    "    \"High-Income Empty Nester\": [\"luxury watch\", \"high-end camera\", \"luxury car\", \"wine fridge\", \"holiday package\"]\n",
    "}\n",
    "\n",
    "emotions = [\"excited\", \"angry\", \"satisfied\", \"frustrated\", \"disappointed\", \"scared\", \"relaxed\", \"confused\", \"amazed\", \"curious\"]\n",
    "\n",
    "# Generate 100 unique combinations\n",
    "combinations = []\n",
    "for _ in range(100):\n",
    "    segment = random.choice(list(segment_products.keys()))\n",
    "    author_id = demographic_df[demographic_df[\"segment\"] == segment][\"uuid\"].sample(1).values[0]\n",
    "    product = random.choice(segment_products[segment])\n",
    "    emotion = random.choice(emotions)\n",
    "    combinations.append({\n",
    "        \"author_id\": author_id,\n",
    "        \"segment\": segment,\n",
    "        \"product\": product,\n",
    "        \"emotion\": emotion\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "combinations_df = pd.DataFrame(combinations)\n",
    "combinations_sdf = spark.createDataFrame(combinations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d125e0b-9ce3-4f29-8dae-f5f077cf4322",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(combinations_sdf.groupBy(\"segment\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ca42901-dd2d-4e24-8923-abc4f963a258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creat temp view for AI_QUERY\n",
    "combinations_sdf.createOrReplaceTempView(\"sampled_audience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "432005b5-6e90-4762-a4a0-62dfebd9ef13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMP VIEW sampled_audience_posts AS\n",
    "SELECT\n",
    "  author_id,\n",
    "  AI_QUERY(\n",
    "    \"databricks-meta-llama-3-3-70b-instruct\", \n",
    "    \"Generate a realistic social media post about a purchase of a \" || product||  \"from the perspective of a \" || segment || \"who is \" || emotion || \"about the product. Make sure you sound like a \" || segment || \". Keep it concise, authentic, and similar to what someone would post on X or Instagram. Include no more than two hashtags and emojis. Don't explicitly mention the segment or that you are an AI assistant. Remove quotation marks.\",\n",
    "    modelParameters => named_struct('max_tokens', 100)\n",
    "  ) AS post\n",
    "FROM sampled_audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a31d4928-7632-4087-b85d-8f09cb6d9e92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "posts_df = spark.sql(\"select * from sampled_audience_posts\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d3384b3-15fa-4f33-b4c1-8dc01b51510c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d92251d9-1990-4d6c-9036-86d81538d227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Save demographic table and write social media posts to volume JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07caee74-6883-4457-9b56-6e26c5767229",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# Generate post id and creation date\n",
    "posts_df.insert(0, 'id', [str(uuid.uuid4()) for _ in range(len(posts_df))])\n",
    "posts_df['created_at'] = [\n",
    "  fake.date_time_between(datetime(2024, 1, 1), datetime(2024, 12, 31)).strftime('%Y-%m-%d %H:%M:%S') for _ in range(len(posts_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b30289-ae82-46ca-9c8b-dc64468f72eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_volume_path = \"/Volumes/jack_sandom/ai_audience_segments/social_media_feed/posts.json\"\n",
    "\n",
    "posts_df.to_json(uc_volume_path, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb40a237-1768-42bf-96ed-d8906376c6b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write demographic data to UC table dropping segment\n",
    "demographic_sdf = spark.createDataFrame(demographic_df)\n",
    "demographic_sdf = demographic_sdf.drop(\"segment\")\n",
    "demographic_sdf.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.audience_demographic\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4389908402265092,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "00. Data Generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
